{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install SentencePiece\n",
        "!pip install accelerate\n",
        "!pip install opencv-python pytesseract requests\n",
        "!pip install tesseract\n",
        "\n",
        "!sudo apt-get install tesseract-ocr\n",
        "!pip install nltk\n",
        "!pip install gradio\n",
        "\n",
        "\n",
        "!apt-get install -y python3-tk\n",
        "!apt-get install xvfb\n",
        "!pip install pyvirtualdisplay\n",
        "\n",
        "!pip install openai\n",
        "!pip install --upgrade accelerate \n",
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "id": "kgBZc80YXvJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae2ae80-ef25-4f9b-dae2-99c18fd62cc2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SentencePiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SentencePiece\n",
            "Successfully installed SentencePiece-0.1.99\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.19.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.22.4)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tesseract\n",
            "  Downloading tesseract-0.1.3.tar.gz (45.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tesseract\n",
            "  Building wheel for tesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tesseract: filename=tesseract-0.1.3-py3-none-any.whl size=45562552 sha256=bf19a759196a87636d74f391e01174c019e641fc1ea65c8eb7ce8faae94dccba\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/c9/aa/698c579693e83fdda9ad6d6f0d8f61ed986e27925ef576f109\n",
            "Successfully built tesseract\n",
            "Installing collected packages: tesseract\n",
            "Successfully installed tesseract-0.1.3\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 4,850 kB of archives.\n",
            "After this operation, 16.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1 [1,598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr amd64 4.1.1-2build2 [262 kB]\n",
            "Fetched 4,850 kB in 1s (5,659 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 122518 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2build2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2build2) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2build2) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.30.0-py3-none-any.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles (from gradio)\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting aiohttp (from gradio)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.95.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client>=0.2.4 (from gradio)\n",
            "  Downloading gradio_client-0.2.4-py3-none-any.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.9/287.9 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.14.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio)\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gradio) (1.22.4)\n",
            "Collecting orjson (from gradio)\n",
            "  Downloading orjson-3.8.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio) (8.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.7)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.14.0)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio) (2.27.1)\n",
            "Collecting semantic-version (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0 (from gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.4->gradio) (2023.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.4->gradio) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio) (3.12.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2022.7.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->gradio)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->gradio)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->gradio)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->gradio)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->gradio)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting starlette<0.27.0,>=0.26.1 (from fastapi->gradio)\n",
            "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2022.12.7)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio)\n",
            "  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio) (1.26.15)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=0b5ae71fd5f9552ddf1f320bb0f573eb2095b4f545c7902a2e44c60ba3f54828\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uc-micro-py, semantic-version, python-multipart, orjson, multidict, h11, frozenlist, async-timeout, aiofiles, yarl, uvicorn, starlette, mdit-py-plugins, linkify-it-py, httpcore, aiosignal, httpx, fastapi, aiohttp, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 fastapi-0.95.1 ffmpy-0.3.0 frozenlist-1.3.3 gradio-3.30.0 gradio-client-0.2.4 h11-0.14.0 httpcore-0.17.0 httpx-0.24.0 linkify-it-py-2.0.2 mdit-py-plugins-0.3.3 multidict-6.0.4 orjson-3.8.12 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.26.1 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3 yarl-1.9.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  blt tk8.6-blt2.5\n",
            "Suggested packages:\n",
            "  blt-demo tix python3-tk-dbg\n",
            "The following NEW packages will be installed:\n",
            "  blt python3-tk tk8.6-blt2.5\n",
            "0 upgraded, 3 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 681 kB of archives.\n",
            "After this operation, 2,947 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 tk8.6-blt2.5 amd64 2.5.3+dfsg-4 [572 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 blt amd64 2.5.3+dfsg-4 [4,944 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-tk amd64 3.8.10-0ubuntu1~20.04 [104 kB]\n",
            "Fetched 681 kB in 1s (1,181 kB/s)\n",
            "Selecting previously unselected package tk8.6-blt2.5.\n",
            "(Reading database ... 122565 files and directories currently installed.)\n",
            "Preparing to unpack .../tk8.6-blt2.5_2.5.3+dfsg-4_amd64.deb ...\n",
            "Unpacking tk8.6-blt2.5 (2.5.3+dfsg-4) ...\n",
            "Selecting previously unselected package blt.\n",
            "Preparing to unpack .../blt_2.5.3+dfsg-4_amd64.deb ...\n",
            "Unpacking blt (2.5.3+dfsg-4) ...\n",
            "Selecting previously unselected package python3-tk:amd64.\n",
            "Preparing to unpack .../python3-tk_3.8.10-0ubuntu1~20.04_amd64.deb ...\n",
            "Unpacking python3-tk:amd64 (3.8.10-0ubuntu1~20.04) ...\n",
            "Setting up tk8.6-blt2.5 (2.5.3+dfsg-4) ...\n",
            "Setting up blt (2.5.3+dfsg-4) ...\n",
            "Setting up python3-tk:amd64 (3.8.10-0ubuntu1~20.04) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 7,697 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libfontenc1 amd64 1:1.1.4-0ubuntu1 [14.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libxfont2 amd64 1:2.0.3-1 [91.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/main amd64 libxkbfile1 amd64 1:1.1.0-1 [65.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 x11-xkb-utils amd64 7.7+5 [158 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu1 [573 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-utils amd64 1:7.7+6 [91.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 xserver-common all 2:1.20.13-1ubuntu1~20.04.8 [27.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 xvfb amd64 2:1.20.13-1ubuntu1~20.04.8 [780 kB]\n",
            "Fetched 7,697 kB in 1s (9,687 kB/s)\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 122630 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-0ubuntu1_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.3-1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.3-1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu1_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu1) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a1.20.13-1ubuntu1~20.04.8_all.deb ...\n",
            "Unpacking xserver-common (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a1.20.13-1ubuntu1~20.04.8_amd64.deb ...\n",
            "Unpacking xvfb (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.3-1) ...\n",
            "Setting up x11-xkb-utils (7.7+5) ...\n",
            "Setting up xfonts-utils (1:7.7+6) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Setting up xvfb (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0Yn4G3qSH0nw"
      },
      "outputs": [],
      "source": [
        "#@title Default title text\n",
        "import gradio as gr\n",
        "# import chatbot_function\n",
        "# import summarization_function\n",
        "# import ocr_function\n",
        "\n",
        "# Define the chatbot function for Gradio\n",
        "def chatbot(input_text):\n",
        "    \n",
        "    return input_text\n",
        "\n",
        "# Define the summarization function for Gradio\n",
        "def summarization(input_text):\n",
        "    summary = input_text\n",
        "    return summary\n",
        "\n",
        "# Define the OCR function for Gradio\n",
        "def ocr(image):\n",
        "    text = image\n",
        "    return text\n",
        "\n",
        "# Create the Gradio interface\n",
        "chatbot_interface = gr.Interface(fn=chatbot, inputs=\"text\", outputs=\"text\", title=\"Chatbot\")\n",
        "summarization_interface = gr.Interface(fn=summarization, inputs=\"text\", outputs=\"text\", title=\"Text Summarization\")\n",
        "ocr_interface = gr.Interface(fn=ocr, inputs=\"image\", outputs=\"text\", title=\"OCR\")\n",
        "\n",
        "# Launch the interface(s)\n",
        "chatbot_interface.launch()\n",
        "summarization_interface.launch()\n",
        "ocr_interface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6i3uzekxPYaz"
      },
      "outputs": [],
      "source": [
        "#@title Default title text\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Selector(select,text,img,)\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    select,[\n",
        "        gr.Slider(2, 20, value=4, label=\"Count\", info=\"Choose betwen 2 and 20\"),\n",
        "\n",
        "\n",
        "        gr.Dropdown(\n",
        "            [\"cat\", \"dog\", \"bird\"], label=\"Animal\", info=\"Will add more animals later!\"\n",
        "        ),\n",
        "\n",
        "\n",
        "        gr.CheckboxGroup([\"USA\", \"Japan\", \"Pakistan\"], label=\"Countries\", info=\"Where are they from?\"),\n",
        "\n",
        "\n",
        "        gr.Radio([\"park\", \"zoo\", \"road\"], label=\"Location\", info=\"Where did they go?\"),\n",
        "\n",
        "\n",
        "        gr.Dropdown(\n",
        "            [\"ran\", \"swam\", \"ate\", \"slept\"], value=[\"swam\", \"slept\"], multiselect=True, label=\"Activity\", info=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed auctor, nisl eget ultricies aliquam, nunc nisl aliquet nunc, eget aliquam nisl nunc vel nisl.\"\n",
        "        ),\n",
        "        gr.Checkbox(label=\"Morning\", info=\"Did they do it in the morning?\"),\n",
        "\n",
        "\n",
        "    ],\"text\" )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOr1HEmSRBAI"
      },
      "outputs": [],
      "source": [
        "# import gradio as gr\n",
        "# import random\n",
        "# import time\n",
        "\n",
        "# context = \"\"\n",
        "\n",
        "\n",
        "# def Summer(text):\n",
        "#     return Summer\n",
        "\n",
        "# def Selector(select,text=\"\",img=''):\n",
        "#     print(select)\n",
        "#     if(select in [\"Summarize\"]):\n",
        "#         return(Summer(text))\n",
        "#     else:\n",
        "#         print (\"nothing selected\")\n",
        "#     if(select == \"hi\"):\n",
        "#         print(\"hilo\")\n",
        "#     return (\"bye2\")\n",
        "\n",
        "\n",
        "\n",
        "# with gr.Blocks() as demo:\n",
        "#     select = gr.Dropdown([\"Summarize\", \"ocr\", \"article extraction\"], label=\"Select\")\n",
        "    \n",
        "#     inp = gr.Textbox(placeholder=\"What is your name?\")\n",
        "#     out = gr.Textbox()\n",
        "#     a= inp.change(Selector, select, out)\n",
        "#     print(a)\n",
        "#     value_selected = select.value\n",
        "#     print(value_selected)\n",
        "\n",
        "\n",
        "\n",
        "#     chatbot = gr.Chatbot()\n",
        "#     msg = gr.Textbox()\n",
        "#     clear = gr.Button(\"Clear\")\n",
        "#     if(1):\n",
        "#         gr.Dropdown(\"h\")\n",
        "    \n",
        "#     def respond(message, chat_history):\n",
        "#         bot_message = Selector(a)                         #random.choice([\"How are you?\", \"I love you\", \"I'm very hungry\"])\n",
        "#         chat_history.append((message, bot_message))\n",
        "#         time.sleep(1)\n",
        "#         return \"\", chat_history\n",
        "\n",
        "#     msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "#     clear.click(lambda: None, None, chatbot, queue=False)\n",
        "#     live =True\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bC2RtlY5Axh0"
      },
      "outputs": [],
      "source": [
        "#@title Question Answering(Currentrly replaced by chatting)\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
        "\n",
        "model_name = \"deepset/roberta-base-squad2\"\n",
        "\n",
        "def Question2(msg):\n",
        "    split_string = msg.split(\" context : \")\n",
        "\n",
        "    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    \n",
        "    # a) Get predictions\n",
        "    nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
        "    QA_input = {\n",
        "        'question': split_string[0],\n",
        "        'context': split_string[1]\n",
        "    }\n",
        "    res = nlp(QA_input)\n",
        "    print(res)\n",
        "    print(res[\"answer\"])\n",
        "    return(res[\"answer\"])\n",
        "\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def Chatting(msg):\n",
        "    \n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a chatbot\"},\n",
        "                {\"role\": \"user\", \"content\": msg},\n",
        "            ]\n",
        "    )\n",
        "\n",
        "    result = ''\n",
        "    for choice in response.choices:\n",
        "        result += choice.message.content\n",
        "\n",
        "    return(result)\n",
        "# Extract the generated text from the response\n"
      ],
      "metadata": {
        "id": "3BHdmRePrMep"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfUn3A5Z_Gwo"
      },
      "outputs": [],
      "source": [
        "# #@title Chatting\n",
        "# # pip install accelerate\n",
        "# from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "# def Chatting(msg):\n",
        "#     model = \"google/flan-t5-small\"\n",
        "#     tokenizer = T5Tokenizer.from_pretrained(model)\n",
        "#     model = T5ForConditionalGeneration.from_pretrained(model, device_map=\"auto\")\n",
        "\n",
        "#     input_text = msg\n",
        "#     input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "\n",
        "#     outputs = model.generate(input_ids,max_new_tokens=2000)\n",
        "#     res = tokenizer.decode(outputs[0])\n",
        "#     print(res)\n",
        "#     return(str(res))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "qRsmi21x5sHY",
        "outputId": "bec3cf3e-3700-4b0c-e32b-2c92b8a52a6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import random\n",
        "import time\n",
        "import cv2\n",
        "import pytesseract\n",
        "reply=\"\"\n",
        "\n",
        "\n",
        "\n",
        "def link(text):\n",
        "    print(\"ifweinwfi2n3i029393932923\")\n",
        "    print(text)\n",
        "    if(text in \"ocr\" ):\n",
        "        return{image_input:gr.update(visible=True)}\n",
        "    if(text == \"Summarize\"):\n",
        "        return{Summar:gr.update(visible=True)}\n",
        "    if(text ==\"Text_summarize\"):\n",
        "        return{Just_Summar:gr.update(visible=True)}\n",
        "    if(text in \"none\"):\n",
        "        return{Summar:gr.update(visible=False),\n",
        "               image_input:gr.update(visible=False)}\n",
        "\n",
        "    return text\n",
        "    \n",
        "#*************************************************************((((((((((((((((((((((((((((((((((((((((())))))))))))))))))))*******************************************************\n",
        "\n",
        "def Gpt(input):\n",
        "    import requests\n",
        "\n",
        "    url = \"https://chatgpt-open-ai-nlp.p.rapidapi.com/\"\n",
        "\n",
        "    payload = {\n",
        "        \"prompt\": input,\n",
        "        \"temperature\": \"0.7\"\n",
        "    }\n",
        "    headers = {\n",
        "        \"content-type\": \"application/json\",\n",
        "        \"Type\": \"chatgpt4\",\n",
        "        \"X-RapidAPI-Key\": \"0d978c8881msh5639ecd02824e60p15d4e9jsn0cf90f7c21eb\",\n",
        "        \"X-RapidAPI-Host\": \"chatgpt-open-ai-nlp.p.rapidapi.com\"\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "    print(response.json())\n",
        "    resp = response.json([0])\n",
        "    context = \"\"  \n",
        "    \n",
        "    return (resp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Article(url):\n",
        "    import requests\n",
        "\n",
        "    url = \"https://article-extractor-and-summarizer.p.rapidapi.com/summarize\"\n",
        "\n",
        "    querystring = {\"url\":url,\"length\":\"6\"}\n",
        "\n",
        "    headers = {\n",
        "        \"X-RapidAPI-Key\": \"0d978c8881msh5639ecd02824e60p15d4e9jsn0cf90f7c21eb\",\n",
        "        \"X-RapidAPI-Host\": \"article-extractor-and-summarizer.p.rapidapi.com\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, headers=headers, params=querystring)\n",
        "    res = response.json()\n",
        "    \n",
        "    return(res[\"summary\"] )\n",
        "\n",
        "#*************************************************************((((((((((((((((((((((((((((((((((((((((())))))))))))))))))))*******************************************************\n",
        "\n",
        "\n",
        "\n",
        "def image_to_text(img,msg):\n",
        "    # return (i)\n",
        "  \n",
        "    # Perform OCR on the downloaded images\n",
        "      \n",
        "        # # Convert the image to grayscale\n",
        "        # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "       \n",
        "        # # Apply image thresholding to preprocess the image\n",
        "        # thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "        \n",
        "        # Apply OCR to the image\n",
        "    try:\n",
        "         text = pytesseract.image_to_string(img, lang='eng')\n",
        "    except:\n",
        "         text = pytesseract.image_to_string(img.name, lang='eng')\n",
        "    print(text)\n",
        "    context = text\n",
        "    return([(msg+\" context : \" +text),text])\n",
        "\n",
        "'''\n",
        "        with open('dialogues.txt', 'w') as f:\n",
        "        # Write a single string to the file\n",
        "            f.write(text)\n",
        "'''\n",
        "        #print(f'Text from image_{i}.jpeg:')\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks(theme='rottenlittlecreature/Moon_Goblin') as demo:\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    def respond(message, chat_history):\n",
        "        \n",
        "        bot_message =  Chatting(message)  #Gpt(message) + context     \n",
        "                     \n",
        "        chat_history.append((message, bot_message))\n",
        "        time.sleep(1)\n",
        "        reply=\"\"\n",
        "        return \"\", chat_history\n",
        "\n",
        "    def add_file(history, file):\n",
        "        \n",
        "        history = history + [((file.name,), None)]\n",
        "        \n",
        "        return (history)\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=0.85, min_width=0):\n",
        "            chatbot = gr.Chatbot()\n",
        "            with gr.Row(scale=0.55, min_width=0):\n",
        "                \n",
        "                msg = gr.Textbox()\n",
        "                \n",
        "                with gr.Column(scale=0.2, min_width=0):\n",
        "                    btn2 = gr.UploadButton(\"Context \\n image📁\", file_types=[\"image\", \"video\", \"audio\"])\n",
        "                    clear = gr.Button(\"Clear\")\n",
        "                \n",
        "            \n",
        "            \n",
        "        \n",
        "\n",
        "        with gr.Column(scale=0.38, min_width=0):\n",
        "            select = gr.Dropdown([ \"Summarize\",\"ocr\",\"Text_summarize\",\"none\"], label=\"Select\")\n",
        "\n",
        "           \n",
        "            \n",
        "\n",
        "\n",
        "    with gr.Row(scale=0.45, min_width=0,visible=False) as image_input:\n",
        "    \n",
        "            inp =   gr.Image()\n",
        "            \n",
        "\n",
        "            out = gr.Textbox()\n",
        "    \n",
        "    with gr.Column(scale=0.35, min_width=0,visible=False) as Summar:\n",
        "        link_box_in = gr.Textbox(lable=\"article Link\")\n",
        "        link_box_out = gr.Textbox(lable=\"Summarized article :\")\n",
        "\n",
        "\n",
        "\n",
        "    with gr.Column(scale=0.35, min_width=0,visible=False) as Just_Summar:\n",
        "        full = gr.Textbox(lable=\"Text\")\n",
        "        summarized = gr.Textbox( lable=\"Summarized Text \", value = \"Summarize this text : \")\n",
        "\n",
        "\n",
        "    btn = gr.Button(\"Extract text From image\")\n",
        "    \n",
        "\n",
        "    \n",
        "    link_box_in.submit(Article,link_box_in,link_box_out)\n",
        "    full.submit(Article,link_box_in,link_box_out)\n",
        "\n",
        "# WHEN click extract images, the extracted text will go to msg Textbox and automatically submits the text\n",
        "    btn.click(image_to_text, [inp,msg], [msg,out]).then(respond, [msg, chatbot], [msg, chatbot])\n",
        "    \n",
        "    \n",
        "    #@@@@@@@@@@May be called twice\n",
        "    msg.submit(respond, [ msg, chatbot], [msg, chatbot])\n",
        "\n",
        "    select.select(link,select,[image_input,Summar,Just_Summar])\n",
        "\n",
        "    \n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "#do somethng for conflict in chat and question answer\n",
        "    btn2.upload(image_to_text,[btn2,msg],[msg,out]).then(add_file, [chatbot, btn2], [chatbot]).then(respond, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "    \n",
        "\n",
        "    gr.Examples(examples=[\"/content/images/image_13.jpeg\",\"/content/images/image_17.jpeg\",\"/content/Screenshot 2023-05-11 205250.png\"],inputs=inp, )\n",
        "    # gr.examples ([\"/content/images/image_13.jpeg\",\"/content/images/image_17.jpeg\"],inputs=[out])\n",
        "    \n",
        "\n",
        "demo.launch(debug = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "S8OADtowzLu1",
        "outputId": "012b819d-855e-45a5-a64d-91e1ec6c89c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/1.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/2.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/3.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/4.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/5.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/6.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/7.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/8.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/9.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/10.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/11.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/12.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/13.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/14.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/15.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/16.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/17.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/18.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/19.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/20.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/21.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/22.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/23.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/24.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/25.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/26.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/27.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/28.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/29.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/30.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/31.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/32.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/33.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/34.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/35.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/36.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/37.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/38.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/39.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/40.jpg']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 63>\u001b[0m:\u001b[94m70\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92mdownload\u001b[0m:\u001b[94m22\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/lib/python3.10/\u001b[0m\u001b[1;33mos.py\u001b[0m:\u001b[94m225\u001b[0m in \u001b[92mmakedirs\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 222 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m tail == cdir:           \u001b[2m# xxx/newdir/. exists if xxx/newdir exists\u001b[0m             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 223 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 224 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 225 \u001b[2m│   │   \u001b[0mmkdir(name, mode)                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 226 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mOSError\u001b[0m:                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 227 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 228 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# could give priority to other errors like EACCES or EROFS\u001b[0m                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mFileExistsError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m17\u001b[0m\u001b[1m]\u001b[0m File exists: \u001b[32m'/content/images/0'\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 63&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">70</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">download</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">22</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/lib/python3.10/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">os.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">225</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">makedirs</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 222 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> tail == cdir:           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># xxx/newdir/. exists if xxx/newdir exists</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 223 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 224 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 225 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>mkdir(name, mode)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 226 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">OSError</span>:                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 227 │   │   # Cannot rely on checking for EEXIST, since the operating system</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 228 │   │   # could give priority to other errors like EACCES or EROFS</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FileExistsError: </span><span style=\"font-weight: bold\">[</span>Errno <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span><span style=\"font-weight: bold\">]</span> File exists: <span style=\"color: #008000; text-decoration-color: #008000\">'/content/images/0'</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import requests\n",
        "import urllib.request\n",
        "from io import BytesIO\n",
        "import os\n",
        "\n",
        "\n",
        "# Set the user agent to avoid HTTP 403 error\n",
        "opener = urllib.request.build_opener()\n",
        "opener.addheaders = [('User-Agent', 'Mozilla/5.0')]\n",
        "urllib.request.install_opener(opener)\n",
        "\n",
        "\n",
        "\n",
        "# Directory to save the images\n",
        "save_directory = r\"/content/images/\"\n",
        "\n",
        "\n",
        "def download(image_urls,j):\n",
        "    folder_path = save_directory+str(j)\n",
        "    os.makedirs(folder_path)\n",
        "    folder_path ='/content/images/'\n",
        "    try:\n",
        "        # Download and save the images locally\n",
        "        for i, url in enumerate(image_urls):\n",
        "            with urllib.request.urlopen(url) as url_response:\n",
        "                img_data = url_response.read()\n",
        "                with open(folder_path+ f'image_{i}.jpeg', mode='wb') as f:\n",
        "                    f.write(img_data)\n",
        "    except urllib.error.HTTPError as e:\n",
        "        print(f'Error downloading {url}: {e}')\n",
        "        print(i)\n",
        "        \n",
        "    \n",
        "'''\n",
        "def OCR(image_urls,j):\n",
        "\n",
        "    folder_path = save_directory+'20'+str(j+1) +'\\\\'\n",
        "\n",
        "    # Perform OCR on the downloaded images\n",
        "    for i in range(22):\n",
        "        # Load the image\n",
        "        image = cv2.imread(folder_path + f'image_{i}.jpeg')\n",
        "\n",
        "        # Convert the image to grayscale\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply image thresholding to preprocess the image\n",
        "        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "        # Apply OCR to the image\n",
        "        text = pytesseract.image_to_string(thresh, lang='eng')\n",
        "\n",
        "        with open('dialogues.txt', 'w') as f:\n",
        "        # Write a single string to the file\n",
        "            f.write(text)\n",
        "\n",
        "        #print(f'Text from image_{i}.jpeg:')\n",
        "        print(text)\n",
        "\n",
        "'''\n",
        "for j in range(2):\n",
        "    image_url =[]\n",
        "    for i in range(40):\n",
        "        image_url.append(f\"https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%20{j}/{i+1}.jpg\")\n",
        "    print(image_url)\n",
        "     \n",
        "    # OCR(image_url,j)\n",
        "    download(image_url,j) \n",
        "\n",
        "# print(image_url)\n",
        "# \n",
        "\n",
        "   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECuBf766MI-x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KG84sy5gLrho"
      },
      "outputs": [],
      "source": [
        "#@title For Image information\n",
        "import torch\n",
        "import requests\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForQuestionAnswering\n",
        "\n",
        "processor = BlipProcessor.from_pretrained(\"ybelkada/blip-vqa-base\")\n",
        "model = BlipForQuestionAnswering.from_pretrained(\"ybelkada/blip-vqa-base\", torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "img_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg' \n",
        "raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
        "\n",
        "question = \"how many dogs are in the picture?\"\n",
        "inputs = processor(raw_image, question, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
        "\n",
        "out = model.generate(**inputs)\n",
        "print(processor.decode(out[0], skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title error\n",
        "import gradio as gr\n",
        "import random\n",
        "import time\n",
        "import cv2\n",
        "import pytesseract\n",
        "reply=\"\"\n",
        "\n",
        "t=\"0\"\n",
        "\n",
        "def link(text):\n",
        "    print(\"ifweinwfi2n3i029393932923\")\n",
        "    print(text)\n",
        "    if(text in \"ocr\" ):\n",
        "        return{image_input:gr.update(visible=True)}\n",
        "    if(text == \"Summarize\"):\n",
        "        return{Summar:gr.update(visible=True)}\n",
        "    if(text ==\"Text_summarize\"):\n",
        "        return{Just_Summar:gr.update(visible=True)}\n",
        "    if(text in \"none\"):\n",
        "        return{Summar:gr.update(visible=False),\n",
        "               image_input:gr.update(visible=False)}\n",
        "\n",
        "    return text\n",
        "    \n",
        "#*************************************************************((((((((((((((((((((((((((((((((((((((((())))))))))))))))))))*******************************************************\n",
        "\n",
        "def Gpt(input):\n",
        "    import requests\n",
        "\n",
        "    url = \"https://chatgpt-open-ai-nlp.p.rapidapi.com/\"\n",
        "\n",
        "    payload = {\n",
        "        \"prompt\": input,\n",
        "        \"temperature\": \"0.7\"\n",
        "    }\n",
        "    headers = {\n",
        "        \"content-type\": \"application/json\",\n",
        "        \"Type\": \"chatgpt4\",\n",
        "        \"X-RapidAPI-Key\": \"0d978c8881msh5639ecd02824e60p15d4e9jsn0cf90f7c21eb\",\n",
        "        \"X-RapidAPI-Host\": \"chatgpt-open-ai-nlp.p.rapidapi.com\"\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "    print(response.json())\n",
        "    resp = response.json([0])\n",
        "    context = \"\"  \n",
        "    \n",
        "    return (resp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Article(url):\n",
        "    import requests\n",
        "\n",
        "    url = \"https://article-extractor-and-summarizer.p.rapidapi.com/summarize\"\n",
        "\n",
        "    querystring = {\"url\":url,\"length\":\"6\"}\n",
        "\n",
        "    headers = {\n",
        "        \"X-RapidAPI-Key\": \"0d978c8881msh5639ecd02824e60p15d4e9jsn0cf90f7c21eb\",\n",
        "        \"X-RapidAPI-Host\": \"article-extractor-and-summarizer.p.rapidapi.com\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, headers=headers, params=querystring)\n",
        "    res = response.json()\n",
        "    \n",
        "    return(res[\"summary\"] )\n",
        "\n",
        "#*************************************************************((((((((((((((((((((((((((((((((((((((((())))))))))))))))))))*******************************************************\n",
        "\n",
        "\n",
        "\n",
        "def image_to_text(img,msg):\n",
        "    # return (i)\n",
        "  \n",
        "    # Perform OCR on the downloaded images\n",
        "      \n",
        "        # # Convert the image to grayscale\n",
        "        # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "       \n",
        "        # # Apply image thresholding to preprocess the image\n",
        "        # thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "        \n",
        "        # Apply OCR to the image\n",
        "    try:\n",
        "         text = pytesseract.image_to_string(img, lang='eng')\n",
        "    except:\n",
        "         text = pytesseract.image_to_string(img.name, lang='eng')\n",
        "    print(text)\n",
        "    context = text\n",
        "    return([(msg+\" context : \" +text),text])\n",
        "\n",
        "'''\n",
        "        with open('dialogues.txt', 'w') as f:\n",
        "        # Write a single string to the file\n",
        "            f.write(text)\n",
        "'''\n",
        "        #print(f'Text from image_{i}.jpeg:')\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks(theme='rottenlittlecreature/Moon_Goblin') as demo:\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    def respond(t,message, chat_history):\n",
        "        if(t==\"0\"):\n",
        "\n",
        "            bot_message =  Chatting(message)  #Gpt(message) + context     \n",
        "        else:\n",
        "            bot_message =  Question2(message)\n",
        "        chat_history.append((message, bot_message))\n",
        "        time.sleep(1)\n",
        "       \n",
        "        return \"\", chat_history\n",
        "\n",
        "    def add_file(history, file):\n",
        "        \n",
        "        history = history + [((file.name,), None)]\n",
        "        \n",
        "        return (history)\n",
        "\n",
        "    with gr.Tab(\"Ai Chatting\"):    \n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=0.85, min_width=0):\n",
        "                chatbot = gr.Chatbot()\n",
        "                with gr.Row(scale=0.55, min_width=0):\n",
        "                    \n",
        "                    msg = gr.Textbox()\n",
        "                    \n",
        "                    with gr.Column(scale=0.2, min_width=0):\n",
        "                        btn2 = gr.UploadButton(\"Context \\n image📁\", file_types=[\"image\", \"video\", \"audio\"])\n",
        "                        clear = gr.Button(\"Clear\")\n",
        "                    \n",
        "    with gr.Tab(\"Context based\"):  \n",
        "           with gr.Row():\n",
        "            with gr.Column(scale=0.85, min_width=0):\n",
        "                chatbot2 = gr.Chatbot()\n",
        "                with gr.Row(scale=0.55, min_width=0):\n",
        "                    \n",
        "                    msg2 = gr.Textbox()\n",
        "                    \n",
        "                    with gr.Column(scale=0.2, min_width=0):\n",
        "                        btn2_ = gr.UploadButton(\"Context \\n image📁\", file_types=[\"image\", \"video\", \"audio\"])\n",
        "                        clear2 = gr.Button(\"Clear\")\n",
        "                \n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    with gr.Column(scale=0.38, min_width=0):\n",
        "            select = gr.Dropdown([ \"Summarize\",\"ocr\",\"Text_summarize\",\"none\"], label=\"Select\")\n",
        "\n",
        "           \n",
        "            \n",
        "\n",
        "\n",
        "    with gr.Row(scale=0.45, min_width=0,visible=False) as image_input:\n",
        "    \n",
        "            inp =   gr.Image()\n",
        "            \n",
        "\n",
        "            out = gr.Textbox()\n",
        "    \n",
        "    with gr.Column(scale=0.35, min_width=0,visible=False) as Summar:\n",
        "        link_box_in = gr.Textbox(lable=\"article Link\")\n",
        "        link_box_out = gr.Textbox(lable=\"Summarized article :\")\n",
        "\n",
        "\n",
        "\n",
        "    with gr.Column(scale=0.35, min_width=0,visible=False) as Just_Summar:\n",
        "        full = gr.Textbox(lable=\"Text\")\n",
        "        summarized = gr.Textbox( lable=\"Summarized Text \", value = \"Summarize this text : \")\n",
        "\n",
        "\n",
        "    btn = gr.Button(\"Extract text From image\")\n",
        "    \n",
        "\n",
        "    \n",
        "    link_box_in.submit(Article,link_box_in,link_box_out)\n",
        "    full.submit(Article,link_box_in,link_box_out)\n",
        "\n",
        "# WHEN click extract images, the extracted text will go to msg Textbox and automatically submits the text\n",
        "    btn.click(image_to_text, [inp,msg], [msg,out]).then(respond, [\"0\",msg, chatbot], [msg, chatbot])\n",
        "    \n",
        "    select.select(link,select,[image_input,Summar,Just_Summar])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #@@@@@@@@@@May be called twice\n",
        "    msg.submit(respond, [ \"0\",msg, chatbot], [msg, chatbot])\n",
        "    msg2.submit(respond, [\"1\", msg2, chatbot2], [msg2, chatbot2])\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "    clear2.click(lambda: None, None, chatbot2, queue=False)\n",
        "#do somethng for conflict in chat and question answer\n",
        "    btn2.upload(image_to_text,[btn2,msg],[msg,out]).then(add_file, [chatbot, btn2], [chatbot]).then(respond, [\"0\",msg, chatbot], [msg, chatbot])\n",
        "    btn2_.upload(image_to_text,[btn2_,msg2],[msg2,out]).then(add_file, [chatbot2, btn2_], [chatbot2]).then(respond, [\"1\",msg2, chatbot2], [msg2, chatbot2])\n",
        "\n",
        "    \n",
        "\n",
        "    gr.Examples(examples=[\"/content/images/image_13.jpeg\",\"/content/images/image_17.jpeg\",\"/content/Screenshot 2023-05-11 205250.png\"],inputs=inp, )\n",
        "    # gr.examples ([\"/content/images/image_13.jpeg\",\"/content/images/image_17.jpeg\"],inputs=[out])\n",
        "    \n",
        "\n",
        "demo.launch(debug = True,share=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0qbBRxL3quky"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}