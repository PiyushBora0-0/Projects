{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiyushBora0-0/Projects/blob/main/Project%202%20working%20tab%2015may.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install SentencePiece\n",
        "!pip install accelerate\n",
        "!pip install opencv-python pytesseract requests\n",
        "!pip install tesseract\n",
        "!sudo apt-get install tesseract-ocr\n",
        "!pip install nltk\n",
        "!pip install gradio\n",
        "\n",
        "\n",
        "!apt-get install -y python3-tk\n",
        "!apt-get install xvfb\n",
        "\n",
        "!pip install openai\n",
        "!pip install --upgrade accelerate \n",
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "id": "kgBZc80YXvJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "333651f8-369f-48a1-86bb-a407aba59dd3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SentencePiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.22.4)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tesseract in /usr/local/lib/python3.10/dist-packages (0.1.3)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2build2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (3.30.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.10/dist-packages (from gradio) (23.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio) (3.8.4)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.95.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.0)\n",
            "Requirement already satisfied: gradio-client>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.2.4)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.14.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gradio) (1.22.4)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from gradio) (3.8.12)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio) (8.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.14.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio) (2.27.1)\n",
            "Requirement already satisfied: semantic-version in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.22.0)\n",
            "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.4->gradio) (2023.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.4->gradio) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio) (3.12.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2022.7.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.26.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2022.12.7)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (0.17.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio) (1.26.15)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-tk is already the newest version (3.8.10-0ubuntu1~20.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.20.13-1ubuntu1~20.04.8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.6)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0Yn4G3qSH0nw"
      },
      "outputs": [],
      "source": [
        "#@title Default title text\n",
        "import gradio as gr\n",
        "# import chatbot_function\n",
        "# import summarization_function\n",
        "# import ocr_function\n",
        "\n",
        "# Define the chatbot function for Gradio\n",
        "def chatbot(input_text):\n",
        "    \n",
        "    return input_text\n",
        "\n",
        "# Define the summarization function for Gradio\n",
        "def summarization(input_text):\n",
        "    summary = input_text\n",
        "    return summary\n",
        "\n",
        "# Define the OCR function for Gradio\n",
        "def ocr(image):\n",
        "    text = image\n",
        "    return text\n",
        "\n",
        "# Create the Gradio interface\n",
        "chatbot_interface = gr.Interface(fn=chatbot, inputs=\"text\", outputs=\"text\", title=\"Chatbot\")\n",
        "summarization_interface = gr.Interface(fn=summarization, inputs=\"text\", outputs=\"text\", title=\"Text Summarization\")\n",
        "ocr_interface = gr.Interface(fn=ocr, inputs=\"image\", outputs=\"text\", title=\"OCR\")\n",
        "\n",
        "# Launch the interface(s)\n",
        "chatbot_interface.launch()\n",
        "summarization_interface.launch()\n",
        "ocr_interface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6i3uzekxPYaz"
      },
      "outputs": [],
      "source": [
        "#@title Default title text\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Selector(select,text,img,)\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    select,[\n",
        "        gr.Slider(2, 20, value=4, label=\"Count\", info=\"Choose betwen 2 and 20\"),\n",
        "\n",
        "\n",
        "        gr.Dropdown(\n",
        "            [\"cat\", \"dog\", \"bird\"], label=\"Animal\", info=\"Will add more animals later!\"\n",
        "        ),\n",
        "\n",
        "\n",
        "        gr.CheckboxGroup([\"USA\", \"Japan\", \"Pakistan\"], label=\"Countries\", info=\"Where are they from?\"),\n",
        "\n",
        "\n",
        "        gr.Radio([\"park\", \"zoo\", \"road\"], label=\"Location\", info=\"Where did they go?\"),\n",
        "\n",
        "\n",
        "        gr.Dropdown(\n",
        "            [\"ran\", \"swam\", \"ate\", \"slept\"], value=[\"swam\", \"slept\"], multiselect=True, label=\"Activity\", info=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed auctor, nisl eget ultricies aliquam, nunc nisl aliquet nunc, eget aliquam nisl nunc vel nisl.\"\n",
        "        ),\n",
        "        gr.Checkbox(label=\"Morning\", info=\"Did they do it in the morning?\"),\n",
        "\n",
        "\n",
        "    ],\"text\" )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOr1HEmSRBAI"
      },
      "outputs": [],
      "source": [
        "# import gradio as gr\n",
        "# import random\n",
        "# import time\n",
        "\n",
        "# context = \"\"\n",
        "\n",
        "\n",
        "# def Summer(text):\n",
        "#     return Summer\n",
        "\n",
        "# def Selector(select,text=\"\",img=''):\n",
        "#     print(select)\n",
        "#     if(select in [\"Summarize\"]):\n",
        "#         return(Summer(text))\n",
        "#     else:\n",
        "#         print (\"nothing selected\")\n",
        "#     if(select == \"hi\"):\n",
        "#         print(\"hilo\")\n",
        "#     return (\"bye2\")\n",
        "\n",
        "\n",
        "\n",
        "# with gr.Blocks() as demo:\n",
        "#     select = gr.Dropdown([\"Summarize\", \"ocr\", \"article extraction\"], label=\"Select\")\n",
        "    \n",
        "#     inp = gr.Textbox(placeholder=\"What is your name?\")\n",
        "#     out = gr.Textbox()\n",
        "#     a= inp.change(Selector, select, out)\n",
        "#     print(a)\n",
        "#     value_selected = select.value\n",
        "#     print(value_selected)\n",
        "\n",
        "\n",
        "\n",
        "#     chatbot = gr.Chatbot()\n",
        "#     msg = gr.Textbox()\n",
        "#     clear = gr.Button(\"Clear\")\n",
        "#     if(1):\n",
        "#         gr.Dropdown(\"h\")\n",
        "    \n",
        "#     def respond(message, chat_history):\n",
        "#         bot_message = Selector(a)                         #random.choice([\"How are you?\", \"I love you\", \"I'm very hungry\"])\n",
        "#         chat_history.append((message, bot_message))\n",
        "#         time.sleep(1)\n",
        "#         return \"\", chat_history\n",
        "\n",
        "#     msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "#     clear.click(lambda: None, None, chatbot, queue=False)\n",
        "#     live =True\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "bC2RtlY5Axh0"
      },
      "outputs": [],
      "source": [
        "#@title Question Answering(Currentrly replaced by chatting)\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
        "\n",
        "model_name = \"deepset/roberta-base-squad2\"\n",
        "\n",
        "def Question2(msg):\n",
        "    split_string = msg.split(\" context : \")\n",
        "\n",
        "    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    \n",
        "    # a) Get predictions\n",
        "    nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
        "    QA_input = {\n",
        "        'question': split_string[0],\n",
        "        'context': split_string[1]\n",
        "    }\n",
        "    res = nlp(QA_input)\n",
        "    print(res)\n",
        "    print(res[\"answer\"])\n",
        "    return(res[\"answer\"])\n",
        "\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "\n",
        "openai.api_key = \"API_Key\"\n",
        "\n",
        "def Chatting(msg):\n",
        "    \n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a chatbot\"},\n",
        "                {\"role\": \"user\", \"content\": msg},\n",
        "            ]\n",
        "    )\n",
        "\n",
        "    result = ''\n",
        "    for choice in response.choices:\n",
        "        result += choice.message.content\n",
        "\n",
        "    return(result)\n"
      ],
      "metadata": {
        "id": "3BHdmRePrMep"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfUn3A5Z_Gwo"
      },
      "outputs": [],
      "source": [
        "# #@title Chatting\n",
        "# # pip install accelerate\n",
        "# from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "# def Chatting(msg):\n",
        "#     model = \"google/flan-t5-small\"\n",
        "#     tokenizer = T5Tokenizer.from_pretrained(model)\n",
        "#     model = T5ForConditionalGeneration.from_pretrained(model, device_map=\"auto\")\n",
        "\n",
        "#     input_text = msg\n",
        "#     input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "\n",
        "#     outputs = model.generate(input_ids,max_new_tokens=2000)\n",
        "#     res = tokenizer.decode(outputs[0])\n",
        "#     print(res)\n",
        "#     return(str(res))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRsmi21x5sHY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c7192ab1-290e-43b7-88c1-64fb48f5ca08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Row, please remove them: {'scale': 0.85, 'min_width': 0}\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Row, please remove them: {'scale': 0.55, 'min_width': 0}\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Checkbox, please remove them: {'lable': 'use threshold'}\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Row, please remove them: {'scale': 0.45, 'min_width': 0}\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7861, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ifweinwfi2n3i029393932923\n",
            "ocr\n",
            "use threshold\n",
            "In the example above, the “engine* parameter specifies which language model to use (in\n",
            "this case, the “davinci* engine). The “prompt” parameter provides the user input to the\n",
            "model, and the “max_tokens* parameter sets the maximum number of tokens (words or\n",
            "characters) that the model can generate in response. The “temperature™ parameter\n",
            "controls the creativity of the generated text, with lower values producing more conservative\n",
            "responses and higher values producing more creative responses.\n",
            "\n",
            "is\n",
            "\n",
            "Use the generated text as your chatbot's response to the user input.\n",
            "\f\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import time\n",
        "import cv2\n",
        "import pytesseract\n",
        "\n",
        "opt =\"\"\n",
        "\n",
        "\n",
        "\n",
        "def link(text):\n",
        "    print(\"ifweinwfi2n3i029393932923\")\n",
        "    print(text)\n",
        "    if(text in \"ocr\" ):\n",
        "        return{image_input:gr.update(visible=True)}\n",
        "    if(text == \"Summarize\"):\n",
        "        return{Summar:gr.update(visible=True)}\n",
        "    if(text ==\"Text_summarize\"):\n",
        "        return{Just_Summar:gr.update(visible=True)}\n",
        "    if(text in \"none\"):\n",
        "        return{Summar:gr.update(visible=False),\n",
        "               image_input:gr.update(visible=False),\n",
        "               Just_Summar:gr.update(visible=False)}\n",
        "\n",
        "    return text\n",
        "    \n",
        "#*************************************************************((((((((((((((((((((((((((((((((((((((((())))))))))))))))))))*******************************************************\n",
        "\n",
        "def Gpt(input):\n",
        "    import requests\n",
        "\n",
        "    url = \"https://chatgpt-open-ai-nlp.p.rapidapi.com/\"\n",
        "\n",
        "    payload = {\n",
        "        \"prompt\": input,\n",
        "        \"temperature\": \"0.7\"\n",
        "    }\n",
        "    headers = {\n",
        "        \"content-type\": \"application/json\",\n",
        "        \"Type\": \"chatgpt4\",\n",
        "        \"X-RapidAPI-Key\": \"0d978c8881msh5639ecd02824e60p15d4e9jsn0cf90f7c21eb\",\n",
        "        \"X-RapidAPI-Host\": \"chatgpt-open-ai-nlp.p.rapidapi.com\"\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "    print(response.json())\n",
        "    resp = response.json([0])\n",
        "    context = \"\"  \n",
        "    \n",
        "    return (resp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Article(url):\n",
        "    import requests\n",
        "\n",
        "    url = \"https://article-extractor-and-summarizer.p.rapidapi.com/summarize\"\n",
        "\n",
        "    querystring = {\"url\":url,\"length\":\"6\"}\n",
        "\n",
        "    headers = {\n",
        "        \"X-RapidAPI-Key\": \"0d978c8881msh5639ecd02824e60p15d4e9jsn0cf90f7c21eb\",\n",
        "        \"X-RapidAPI-Host\": \"article-extractor-and-summarizer.p.rapidapi.com\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, headers=headers, params=querystring)\n",
        "    res = response.json()\n",
        "    \n",
        "    return(res[\"summary\"] )\n",
        "\n",
        "#*************************************************************((((((((((((((((((((((((((((((((((((((((())))))))))))))))))))*******************************************************\n",
        "\n",
        "\n",
        "def ocr_opt(flag):\n",
        "\n",
        "    if(flag):\n",
        "        opt = \"use threshold\"\n",
        "    else:\n",
        "        opt = \"\"\n",
        "    print(opt)\n",
        "    return\n",
        "\n",
        "def image_to_text(img,msg):\n",
        "    # return (i)\n",
        "  \n",
        "    # Perform OCR on the downloaded images\n",
        "      \n",
        "        # # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "       \n",
        "        # # Apply image thresholding to preprocess the image\n",
        "    if(opt == \"use threshold\"):\n",
        "        print(\"threshold used\")\n",
        "        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "        grey = thresh\n",
        "        \n",
        "        # Apply OCR to the image\n",
        "    try:\n",
        "         text = pytesseract.run_and_get_output(gray, lang='eng',extension='txt', config=\"words\")\n",
        "    except:\n",
        "         text = pytesseract.image_to_string(gray.name, lang='eng',extension='txt', config=\"words\")\n",
        "    print(text)\n",
        "    context = text\n",
        "    return([text,text])\n",
        "\n",
        "'''\n",
        "        with open('dialogues.txt', 'w') as f:\n",
        "        # Write a single string to the file\n",
        "            f.write(text)\n",
        "'''\n",
        "        #print(f'Text from image_{i}.jpeg:')\n",
        "\n",
        "\n",
        "#theme='freddyaboulton/dracula_revamped'\n",
        "#theme='rottenlittlecreature/Moon_Goblin'\n",
        "\n",
        "with gr.Blocks(theme='rottenlittlecreature/Moon_Goblin') as demo:\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    def respond(message, chat_history):\n",
        "        \n",
        "        bot_message =  Chatting(message)  #Gpt(message) + context     \n",
        "                     \n",
        "        chat_history.append((message, bot_message))\n",
        "        time.sleep(1)\n",
        "        \n",
        "        return \"\", chat_history\n",
        "    def respond2(message, chat_history):\n",
        "        \n",
        "        bot_message =  Question2(message)  #Gpt(message) + context     \n",
        "                     \n",
        "        chat_history.append((message, bot_message))\n",
        "        time.sleep(1)\n",
        "        \n",
        "        return \"\", chat_history\n",
        "\n",
        "    def add_file(history, file):\n",
        "        \n",
        "        history = history + [((file.name,), None)]\n",
        "        \n",
        "        return (history)\n",
        "    def add_file2(history, file):\n",
        "        \n",
        "        history = history + [((file.name,), None)]\n",
        "        \n",
        "        return (history)\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    with gr.Tab(\"Gpt\"):      \n",
        "        gr.Markdown(\"Type in the textbox below, use context image to upload image for context or use ocr tab to first convert img to text\"  )\n",
        "        with gr.Row(scale=0.85, min_width=0):\n",
        "            with gr.Column(scale=1,):\n",
        "                chatbot = gr.Chatbot()\n",
        "                with gr.Row(scale=0.55, min_width=0):\n",
        "                        \n",
        "                    msg = gr.Textbox()\n",
        "                        \n",
        "                    with gr.Column(scale=0.2, min_width=0):\n",
        "                        btn2 = gr.UploadButton(\"Context \\n image📁\", file_types=[\"image\", \"video\", \"audio\"])\n",
        "                        clear = gr.Button(\"Clear\")\n",
        "        \n",
        "            \n",
        "\n",
        "            with gr.Column(scale=0.3):\n",
        "                select = gr.Dropdown([ \"Summarize\",\"ocr\",\"Text_summarize\",\"none\"], label=\"Select\")\n",
        "\n",
        "           \n",
        "\n",
        "    \n",
        "    with gr.Column(scale=0.45, min_width=0,visible=False) as image_input:\n",
        "        gr.Markdown('''upload image in upload box and click on Extract image Button, you can edit extracted text''')\n",
        "        \n",
        "        \n",
        "        with gr.Column(scale=0.05):\n",
        "            i_opt = gr.Checkbox(lable=\"use threshold\",interactive=True,label=\"use Threshold\")  \n",
        "        with gr.Row(scale=0.45, min_width=0):\n",
        "            inp =   gr.Image()\n",
        "                        \n",
        "            out = gr.Textbox(interactive=True,label=\"extracted text\")\n",
        "        btn = gr.Button(\"Extract text From image\")\n",
        "        \n",
        "    # with gr.Column(scale=0.35, min_width=0,visible=False) as Summar:\n",
        "    #     link_box_in = gr.Textbox(label=\"article \")\n",
        "    #     link_box_out = gr.Textbox(label=\"Summarized  :\",interactive=True)\n",
        "\n",
        "\n",
        "\n",
        "    with gr.Column(scale=0.35, min_width=0,visible=False) as Just_Summar:\n",
        "        full = gr.Textbox(placeholder= \"Enter a paragraph to summarize it:\",label=\"Text\")\n",
        "        summarized = gr.Textbox( label=\"Summarized Text \",interactive=True)\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    # link_box_in.submit(Article,link_box_in,link_box_out)\n",
        "\n",
        "    # full.submit(Article,link_box_in,link_box_out)\n",
        "\n",
        "# WHEN click extract images, the extracted text will go to msg Textbox and automatically submits the text\n",
        "    btn.click(image_to_text, [inp,msg], [msg,out])#.then(respond2, [msgB, chatbotB], [msgB, chatbotB])\n",
        "    \n",
        "    \n",
        "    #@@@@@@@@@@May be called twice\n",
        "    msg.submit(respond, [ msg, chatbot], [msg, chatbot])\n",
        "    \n",
        "\n",
        "\n",
        "    select.select(link,select,[image_input,Just_Summar])\n",
        "\n",
        "    \n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "    \n",
        "#do somethng for conflict in chat and question answer\n",
        "    btn2.upload(image_to_text,[btn2,msg],[msg,out]).then(add_file, [chatbot, btn2], [chatbot]).then(respond, [msg, chatbot], [msg, chatbot])\n",
        "       \n",
        "\n",
        "\n",
        "    i_opt.select(ocr_opt,i_opt,[])\n",
        "\n",
        "    gr.Examples(examples=[\"/content/images/image_13.jpeg\",\"/content/images/image_17.jpeg\",\"/content/Screenshot 2023-05-11 205250.png\"],inputs=inp, )\n",
        "    # gr.examples ([\"/content/images/image_13.jpeg\",\"/content/images/image_17.jpeg\"],inputs=[out])\n",
        "    \n",
        "\n",
        "demo.launch(debug = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ec3jTDxkQ5YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "S8OADtowzLu1",
        "outputId": "449f5b1d-5f39-472f-9bff-77f6f49f94b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/1.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/2.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/3.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/4.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/5.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/6.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/7.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/8.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/9.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/10.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/11.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/12.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/13.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/14.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/15.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/16.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/17.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/18.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/19.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/20.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/21.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/22.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/23.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/24.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/25.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/26.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/27.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/28.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/29.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/30.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/31.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/32.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/33.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/34.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/35.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/36.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/37.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/38.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/39.jpg', 'https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%200/40.jpg']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 61>\u001b[0m:\u001b[94m68\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92mdownload\u001b[0m:\u001b[94m20\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/lib/python3.10/\u001b[0m\u001b[1;33mos.py\u001b[0m:\u001b[94m225\u001b[0m in \u001b[92mmakedirs\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 222 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m tail == cdir:           \u001b[2m# xxx/newdir/. exists if xxx/newdir exists\u001b[0m             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 223 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 224 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 225 \u001b[2m│   │   \u001b[0mmkdir(name, mode)                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 226 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mOSError\u001b[0m:                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 227 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 228 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# could give priority to other errors like EACCES or EROFS\u001b[0m                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mFileExistsError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m17\u001b[0m\u001b[1m]\u001b[0m File exists: \u001b[32m'/content/images/0'\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 61&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">68</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">download</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">20</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/lib/python3.10/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">os.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">225</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">makedirs</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 222 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> tail == cdir:           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># xxx/newdir/. exists if xxx/newdir exists</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 223 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 224 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 225 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>mkdir(name, mode)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 226 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">OSError</span>:                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 227 │   │   # Cannot rely on checking for EEXIST, since the operating system</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 228 │   │   # could give priority to other errors like EACCES or EROFS</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FileExistsError: </span><span style=\"font-weight: bold\">[</span>Errno <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span><span style=\"font-weight: bold\">]</span> File exists: <span style=\"color: #008000; text-decoration-color: #008000\">'/content/images/0'</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "import requests\n",
        "import urllib.request\n",
        "from io import BytesIO\n",
        "import os\n",
        "\n",
        "\n",
        "# Set the user agent to avoid HTTP 403 error\n",
        "opener = urllib.request.build_opener()\n",
        "opener.addheaders = [('User-Agent', 'Mozilla/5.0')]\n",
        "urllib.request.install_opener(opener)\n",
        "\n",
        "\n",
        "\n",
        "# Directory to save the images\n",
        "save_directory = r\"/content/images/\"\n",
        "\n",
        "\n",
        "def download(image_urls,j):\n",
        "    folder_path = save_directory+str(j)\n",
        "    os.makedirs(folder_path)\n",
        "    folder_path ='/content/images/'\n",
        "    try:\n",
        "        # Download and save the images locally\n",
        "        for i, url in enumerate(image_urls):\n",
        "            with urllib.request.urlopen(url) as url_response:\n",
        "                img_data = url_response.read()\n",
        "                with open(folder_path+ f'image_{i}.jpeg', mode='wb') as f:\n",
        "                    f.write(img_data)\n",
        "    except urllib.error.HTTPError as e:\n",
        "        print(f'Error downloading {url}: {e}')\n",
        "        print(i)\n",
        "        \n",
        "    \n",
        "'''\n",
        "def OCR(image_urls,j):\n",
        "\n",
        "    folder_path = save_directory+'20'+str(j+1) +'\\\\'\n",
        "\n",
        "    # Perform OCR on the downloaded images\n",
        "    for i in range(22):\n",
        "        # Load the image\n",
        "        image = cv2.imread(folder_path + f'image_{i}.jpeg')\n",
        "\n",
        "        # Convert the image to grayscale\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply image thresholding to preprocess the image\n",
        "        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "        # Apply OCR to the image\n",
        "        text = pytesseract.image_to_string(thresh, lang='eng')\n",
        "\n",
        "        with open('dialogues.txt', 'w') as f:\n",
        "        # Write a single string to the file\n",
        "            f.write(text)\n",
        "\n",
        "        #print(f'Text from image_{i}.jpeg:')\n",
        "        print(text)\n",
        "\n",
        "'''\n",
        "for j in range(2):\n",
        "    image_url =[]\n",
        "    for i in range(40):\n",
        "        image_url.append(f\"https://www.asurascans.com/wp-content/uploads/custom-upload/38459/6418d938a8d82/%20{j}/{i+1}.jpg\")\n",
        "    print(image_url)\n",
        "     \n",
        "    # OCR(image_url,j)\n",
        "    download(image_url,j) \n",
        "\n",
        "# print(image_url)\n",
        "# \n",
        "\n",
        "   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECuBf766MI-x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KG84sy5gLrho"
      },
      "outputs": [],
      "source": [
        "#@title For Image information\n",
        "import torch\n",
        "import requests\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForQuestionAnswering\n",
        "\n",
        "processor = BlipProcessor.from_pretrained(\"ybelkada/blip-vqa-base\")\n",
        "model = BlipForQuestionAnswering.from_pretrained(\"ybelkada/blip-vqa-base\", torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "img_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg' \n",
        "raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
        "\n",
        "question = \"how many dogs are in the picture?\"\n",
        "inputs = processor(raw_image, question, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
        "\n",
        "out = model.generate(**inputs)\n",
        "print(processor.decode(out[0], skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title error\n",
        "import gradio as gr\n",
        "import random\n",
        "import time\n",
        "import cv2\n",
        "import pytesseract\n",
        "reply=\"\"\n",
        "\n",
        "t=\"0\"\n",
        "\n",
        "def link(text):\n",
        "    print(\"ifweinwfi2n3i029393932923\")\n",
        "    print(text)\n",
        "    if(text in \"ocr\" ):\n",
        "        return{image_input:gr.update(visible=True)}\n",
        "    if(text == \"Summarize\"):\n",
        "        return{Summar:gr.update(visible=True)}\n",
        "    if(text ==\"Text_summarize\"):\n",
        "        return{Just_Summar:gr.update(visible=True)}\n",
        "    if(text in \"none\"):\n",
        "        return{Summar:gr.update(visible=False),\n",
        "               image_input:gr.update(visible=False)}\n",
        "\n",
        "    return text\n",
        "    \n",
        "#*************************************************************((((((((((((((((((((((((((((((((((((((((())))))))))))))))))))*******************************************************\n",
        "\n",
        "def Gpt(input):\n",
        "    import requests\n",
        "\n",
        "    url = \"https://chatgpt-open-ai-nlp.p.rapidapi.com/\"\n",
        "\n",
        "    payload = {\n",
        "        \"prompt\": input,\n",
        "        \"temperature\": \"0.7\"\n",
        "    }\n",
        "    headers = {\n",
        "        \"content-type\": \"application/json\",\n",
        "        \"Type\": \"chatgpt4\",\n",
        "        \"X-RapidAPI-Key\": \"0d978c8881msh5639ecd02824e60p15d4e9jsn0cf90f7c21eb\",\n",
        "        \"X-RapidAPI-Host\": \"chatgpt-open-ai-nlp.p.rapidapi.com\"\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "    print(response.json())\n",
        "    resp = response.json([0])\n",
        "    context = \"\"  \n",
        "    \n",
        "    return (resp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Article(url):\n",
        "    import requests\n",
        "\n",
        "    url = \"https://article-extractor-and-summarizer.p.rapidapi.com/summarize\"\n",
        "\n",
        "    querystring = {\"url\":url,\"length\":\"6\"}\n",
        "\n",
        "    headers = {\n",
        "        \"X-RapidAPI-Key\": \"0d978c8881msh5639ecd02824e60p15d4e9jsn0cf90f7c21eb\",\n",
        "        \"X-RapidAPI-Host\": \"article-extractor-and-summarizer.p.rapidapi.com\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, headers=headers, params=querystring)\n",
        "    res = response.json()\n",
        "    \n",
        "    return(res[\"summary\"] )\n",
        "\n",
        "#*************************************************************((((((((((((((((((((((((((((((((((((((((())))))))))))))))))))*******************************************************\n",
        "\n",
        "\n",
        "\n",
        "def image_to_text(img,msg):\n",
        "    # return (i)\n",
        "  \n",
        "    # Perform OCR on the downloaded images\n",
        "      \n",
        "        # # Convert the image to grayscale\n",
        "        # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "       \n",
        "        # # Apply image thresholding to preprocess the image\n",
        "        # thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "        \n",
        "        # Apply OCR to the image\n",
        "    try:\n",
        "         text = pytesseract.image_to_string(img, lang='eng')\n",
        "    except:\n",
        "         text = pytesseract.image_to_string(img.name, lang='eng')\n",
        "    print(text)\n",
        "    context = text\n",
        "    return([(msg+\" context : \" +text),text])\n",
        "\n",
        "'''\n",
        "        with open('dialogues.txt', 'w') as f:\n",
        "        # Write a single string to the file\n",
        "            f.write(text)\n",
        "'''\n",
        "        #print(f'Text from image_{i}.jpeg:')\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks(theme='rottenlittlecreature/Moon_Goblin') as demo:\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    def respond(t,message, chat_history):\n",
        "        if(t==\"0\"):\n",
        "\n",
        "            bot_message =  Chatting(message)  #Gpt(message) + context     \n",
        "        else:\n",
        "            bot_message =  Question2(message)\n",
        "        chat_history.append((message, bot_message))\n",
        "        time.sleep(1)\n",
        "       \n",
        "        return \"\", chat_history\n",
        "\n",
        "    def add_file(history, file):\n",
        "        \n",
        "        history = history + [((file.name,), None)]\n",
        "        \n",
        "        return (history)\n",
        "\n",
        "    with gr.Tab(\"Ai Chatting\"):    \n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=0.85, min_width=0):\n",
        "                chatbot = gr.Chatbot()\n",
        "                with gr.Row(scale=0.55, min_width=0):\n",
        "                    \n",
        "                    msg = gr.Textbox()\n",
        "                    \n",
        "                    with gr.Column(scale=0.2, min_width=0):\n",
        "                        btn2 = gr.UploadButton(\"Context \\n image📁\", file_types=[\"image\", \"video\", \"audio\"])\n",
        "                        clear = gr.Button(\"Clear\")\n",
        "                    \n",
        "    with gr.Tab(\"Context based\"):  \n",
        "           with gr.Row():\n",
        "            with gr.Column(scale=0.85, min_width=0):\n",
        "                chatbot2 = gr.Chatbot()\n",
        "                with gr.Row(scale=0.55, min_width=0):\n",
        "                    \n",
        "                    msg2 = gr.Textbox()\n",
        "                    \n",
        "                    with gr.Column(scale=0.2, min_width=0):\n",
        "                        btn2_ = gr.UploadButton(\"Context \\n image📁\", file_types=[\"image\", \"video\", \"audio\"])\n",
        "                        clear2 = gr.Button(\"Clear\")\n",
        "                \n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    with gr.Column(scale=0.38, min_width=0):\n",
        "            select = gr.Dropdown([ \"Summarize\",\"ocr\",\"Text_summarize\",\"none\"], label=\"Select\")\n",
        "\n",
        "           \n",
        "            \n",
        "\n",
        "\n",
        "    with gr.Row(scale=0.45, min_width=0,visible=False) as image_input:\n",
        "    \n",
        "            inp =   gr.Image()\n",
        "            \n",
        "\n",
        "            out = gr.Textbox()\n",
        "    \n",
        "    with gr.Column(scale=0.35, min_width=0,visible=False) as Summar:\n",
        "        link_box_in = gr.Textbox(lable=\"article Link\")\n",
        "        link_box_out = gr.Textbox(lable=\"Summarized article :\")\n",
        "\n",
        "\n",
        "\n",
        "    with gr.Column(scale=0.35, min_width=0,visible=False) as Just_Summar:\n",
        "        full = gr.Textbox(lable=\"Text\")\n",
        "        summarized = gr.Textbox( lable=\"Summarized Text \", value = \"Summarize this text : \")\n",
        "\n",
        "\n",
        "    btn = gr.Button(\"Extract text From image\")\n",
        "    \n",
        "\n",
        "    \n",
        "    link_box_in.submit(Article,link_box_in,link_box_out)\n",
        "    full.submit(Article,link_box_in,link_box_out)\n",
        "\n",
        "# WHEN click extract images, the extracted text will go to msg Textbox and automatically submits the text\n",
        "    btn.click(image_to_text, [inp,msg], [msg,out]).then(respond, [\"0\",msg, chatbot], [msg, chatbot])\n",
        "    \n",
        "    select.select(link,select,[image_input,Summar,Just_Summar])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #@@@@@@@@@@May be called twice\n",
        "    msg.submit(respond, [ \"0\",msg, chatbot], [msg, chatbot])\n",
        "    msg2.submit(respond, [\"1\", msg2, chatbot2], [msg2, chatbot2])\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "    clear2.click(lambda: None, None, chatbot2, queue=False)\n",
        "#do somethng for conflict in chat and question answer\n",
        "    btn2.upload(image_to_text,[btn2,msg],[msg,out]).then(add_file, [chatbot, btn2], [chatbot]).then(respond, [\"0\",msg, chatbot], [msg, chatbot])\n",
        "    btn2_.upload(image_to_text,[btn2_,msg2],[msg2,out]).then(add_file, [chatbot2, btn2_], [chatbot2]).then(respond, [\"1\",msg2, chatbot2], [msg2, chatbot2])\n",
        "\n",
        "    \n",
        "\n",
        "    gr.Examples(examples=[\"/content/images/image_13.jpeg\",\"/content/images/image_17.jpeg\",\"/content/Screenshot 2023-05-11 205250.png\"],inputs=inp, )\n",
        "    # gr.examples ([\"/content/images/image_13.jpeg\",\"/content/images/image_17.jpeg\"],inputs=[out])\n",
        "    \n",
        "\n",
        "demo.launch(debug = True,share=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0qbBRxL3quky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "response = requests.get(\"https://api.example.com/data\")\n",
        "data = response.json()\n",
        "print(data)"
      ],
      "metadata": {
        "id": "oduRd2VT1Hhz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPWaI5XER0pm5s2QC0Kv+Gr",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}